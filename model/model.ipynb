{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data\n",
    "\n",
    "Now that we have a dataframe with 3 columns :  `tokenized` (title + synopsis), `genre` and `length`, we can vectorize the data. We will use the `Bag-of-Words` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elmah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "sys.path.append('../preprocessing')\n",
    "\n",
    "from process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../data/allocine_genres_train.csv')\n",
    "\n",
    "\n",
    "df_train = process_df(df_train)\n",
    "\n",
    "df_train.to_csv('../data/allocine_genres_train_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by vectorizing the data using TF-IDF. TF-IDF stands for `Term Frequency - Inverse Document Frequency`. It is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus. It is often used as a weighting factor in searches of information retrieval, text mining, and user modeling. The TF-IDF value increases proportionally to the number of times a word appears in the document and is offset by the number of documents in the corpus that contain the word, which helps to adjust for the fact that some words appear more frequently in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train['synopsis_title'], df_train['genre'], test_size=0.2, random_state=42)\n",
    "\n",
    "models = []\n",
    "accuracy_scores = []\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,1), max_df=0.85,min_df=0.01,lowercase=False)\n",
    "tfid_X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(tfid_X_train, y_train)\n",
    "\n",
    "tfid_X_test = vectorizer.transform(X_test)\n",
    "y_pred = clf.predict(tfid_X_test)\n",
    "\n",
    "print(\"DecisionTreeClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models.append(\"DecisionTreeClassifier\")\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(tfid_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(tfid_X_test)\n",
    "\n",
    "print(\"MultinomialNB accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models.append(\"MultinomialNB\")\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(tfid_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(tfid_X_test)\n",
    "\n",
    "print(\"LogisticRegression accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models.append(\"LogisticRegression\")\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(tfid_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(tfid_X_test)\n",
    "\n",
    "print(\"RandomForestClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models.append(\"RandomForestClassifier\")\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = AdaBoostClassifier(random_state=42)\n",
    "clf.fit(tfid_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(tfid_X_test)\n",
    "\n",
    "print(\"AdaBoostClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models.append(\"AdaBoostClassifier\")\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(tfid_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(tfid_X_test)\n",
    "\n",
    "print(\"GradientBoostingClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models.append(\"GradientBoostingClassifier\")\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = SGDClassifier(random_state=42)\n",
    "clf.fit(tfid_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(tfid_X_test)\n",
    "\n",
    "print(\"SGDClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models.append(\"SGDClassifier\")\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clf = SVC(random_state=42)\n",
    "clf.fit(tfid_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(tfid_X_test)\n",
    "\n",
    "print(\"SVC accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models.append(\"SVC\")\n",
    "accuracy_scores.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy of each model\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(models, accuracy_scores)\n",
    "plt.title(\"Accuracy of each model\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Logistic Regression has the best score with TF-IDF. We will use this model to predict the genre of the movies.But first, we will try to improve the score by using a different vectorizer like Bag-of-Words."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bag of words\n",
    "\n",
    "models_bow = []\n",
    "accuracy_scores_bow = []\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range = (1,1), max_df=0.85,min_df=0.01,lowercase=False)\n",
    "bow_X_train = vectorizer.fit_transform(X_train)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "clf.fit(bow_X_train, y_train)\n",
    "\n",
    "bow_X_test = vectorizer.transform(X_test)\n",
    "y_pred = clf.predict(bow_X_test)\n",
    "\n",
    "print(\"DecisionTreeClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models_bow.append(\"DecisionTreeClassifier\")\n",
    "accuracy_scores_bow.append(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(bow_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(bow_X_test)\n",
    "\n",
    "print(\"MultinomialNB accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models_bow.append(\"MultinomialNB\")\n",
    "accuracy_scores_bow.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(bow_X_test)\n",
    "\n",
    "print(\"LogisticRegression accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models_bow.append(\"LogisticRegression\")\n",
    "accuracy_scores_bow.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(bow_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(bow_X_test)\n",
    "\n",
    "print(\"RandomForestClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models_bow.append(\"RandomForestClassifier\")\n",
    "accuracy_scores_bow.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(random_state=42)\n",
    "clf.fit(bow_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(bow_X_test)\n",
    "\n",
    "print(\"AdaBoostClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models_bow.append(\"AdaBoostClassifier\")\n",
    "accuracy_scores_bow.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(random_state=42)\n",
    "clf.fit(bow_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(bow_X_test)\n",
    "\n",
    "print(\"GradientBoostingClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models_bow.append(\"GradientBoostingClassifier\")\n",
    "accuracy_scores_bow.append(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SGDClassifier(random_state=42)\n",
    "clf.fit(bow_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(bow_X_test)\n",
    "\n",
    "print(\"SGDClassifier accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models_bow.append(\"SGDClassifier\")\n",
    "accuracy_scores_bow.append(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(random_state=42)\n",
    "clf.fit(bow_X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(bow_X_test)\n",
    "\n",
    "print(\"SVC accuracy : \", accuracy_score(y_test, y_pred))\n",
    "models_bow.append(\"SVC\")\n",
    "accuracy_scores_bow.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the accuracy of each model and compare with tf-idf\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(models, accuracy_scores, label=\"tf-idf\")\n",
    "plt.bar(models_bow, accuracy_scores_bow, label=\"bag of words\")\n",
    "plt.title(\"Accuracy of each model\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Multinomial Naive Bayes has the best score with Bag-of-Words. We will use this model to predict the genre of the movies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now test our model on our test set using the Bag-of-Words vectorizer with Multinomial Naive Bayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model with new data using our best model, bow with MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = MultinomialNB()\n",
    "# clf.fit(bow_X_train, y_train)\n",
    "\n",
    "# # save the model\n",
    "# pickle.dump(clf, open(\"model.pkl\", \"wb\"))\n",
    "# pickle.dump(vectorizer, open(\"vectorizer.pkl\", \"wb\"))\n",
    "\n",
    "\n",
    "# load the model\n",
    "model = pickle.load(open(\"trained_model/model.pkl\", \"rb\"))\n",
    "vectorizer = pickle.load(open(\"trained_model/vectorizer.pkl\", \"rb\"))\n",
    "\n",
    "# test with new data\n",
    "df_test = pd.read_csv('../data/allocine_genres_test.csv')\n",
    "df_test = process_df(df_test)\n",
    "\n",
    "X_test = df_test[\"synopsis_title\"]\n",
    "y_test = df_test[\"genre\"]\n",
    "\n",
    "bow_X_test = vectorizer.transform(X_test)\n",
    "y_pred = model.predict(bow_X_test)\n",
    "\n",
    "print(\"MultinomialNB accuracy : \", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# lets try with a new synopsis\n",
    "synopsis = \"Dans la ville de New York, le détective John Smith est sur la piste d'un tueur en série qui terrorise la ville depuis plusieurs mois. Alors que l'enquête piétine, le meurtrier continue de sévir et les victimes s'accumulent. John, qui est hanté par ses propres démons, est déterminé à arrêter le tueur avant qu'il ne frappe à nouveau. Au fil de l'enquête, John rencontre plusieurs personnages suspects, dont une ex-petite amie du tueur et un membre influent de la mafia locale. Il doit naviguer dans un monde sombre et dangereux pour découvrir la vérité sur l'identité du tueur. Alors que les indices s'accumulent et que la pression monte, John doit faire face à ses propres démons intérieurs et aux doutes de ses collègues. Dans une course contre la montre, il doit résoudre le mystère avant qu'il ne soit trop tard et que le tueur ne frappe de nouveau. Le film est rempli de suspense, de tension et de rebondissements jusqu'à son dénouement final choquant.\"\n",
    "titre = \"Au coeur de la nuit\"\n",
    "\n",
    "synopsis_2 = \"Nous suivons Marie Curie dès ses débuts en Pologne, alors qu'elle doit lutter contre les préjugés de genre pour poursuivre ses études scientifiques. Elle rencontre ensuite Pierre Curie, un physicien français, et ils tombent amoureux. Ensemble, ils commencent à travailler sur la radioactivité et découvrent le radium et le polonium, pour lesquels ils reçoivent le prix Nobel de physique en 1903. Mais leur travail n'a pas été facile et ils ont dû surmonter de nombreux obstacles, notamment les préjugés de genre et les réticences de la communauté scientifique. Ils ont également dû faire face à des tragédies personnelles, notamment la mort prématurée de Pierre. Après la mort de Pierre, Marie poursuit ses recherches et devient la première femme professeure à la Sorbonne. Elle reçoit également un deuxième prix Nobel, cette fois en chimie, pour son travail sur les éléments radioactifs. Le film montre comment Marie Curie a changé la face de la science et a ouvert la voie à d'autres femmes scientifiques. Mais il montre également les sacrifices qu'elle a dû faire pour y parvenir, notamment la lutte pour concilier son travail et sa vie de famille. Le film est une célébration de la vie extraordinaire de Marie Curie, une femme qui a brisé les barrières et ouvert la voie à de nouvelles découvertes scientifiques\"\n",
    "titre_2 = \"La vie extraordinaire de Marie Curie\"\n",
    "\n",
    "synopsis_3 = \"Sophie est une jeune femme ambitieuse qui travaille dans une grande entreprise. Elle est passionnée par son travail et sa vie sentimentale est au second plan. Un jour, elle rencontre Jake, un artiste bohème et charismatique. Malgré leurs différences, ils sont attirés l'un par l'autre et commencent une relation. Leur amour est intense et passionné, mais leur relation est mise à rude épreuve par les différences de leurs vies. Sophie doit naviguer dans le monde des arts de Jake, qui est très différent de son monde d'affaires. Et Jake doit faire face aux attentes de Sophie en matière de stabilité et de sécurité financière. Alors que leur relation devient de plus en plus sérieuse, ils doivent faire face à des défis imprévus qui mettent leur amour à l'épreuve. Ils doivent trouver un équilibre entre leurs vies et leurs rêves, tout en restant fidèles l'un à l'autre. Le film montre comment l'amour peut être imprévisible et inattendu, et comment il peut nous amener à repenser nos priorités et nos choix de vie. Les personnages principaux sont confrontés à des choix difficiles, mais ils sont prêts à tout pour leur amour. Le film est rempli de scènes romantiques, de moments d'humour et d'émotion, et offre une belle réflexion sur la vie et l'amour.\"\n",
    "titre_3 = \"Un Amour Inattendu\"\n",
    "\n",
    "synopsis_4 = \"Un groupe d'amis décide de passer un week-end dans une vieille maison isolée dans les bois. Mais dès leur arrivée, ils commencent à ressentir une étrange présence et à entendre des bruits inexpliqués. Bientôt, ils se rendent compte que la maison est hantée par des esprits maléfiques qui cherchent à les effrayer et à les tuer.Les amis tentent de quitter la maison, mais ils se retrouvent pris au piège par des phénomènes paranormaux terrifiants. Ils découvrent des indices sur le passé sombre de la maison et sur les esprits qui la hantent. Mais plus ils enquêtent, plus les esprits deviennent violents. Les amis doivent alors faire face à leurs peurs les plus profondes et unir leurs forces pour survivre aux attaques des esprits maléfiques. Ils se rendent compte que pour échapper à la maison hantée, ils doivent résoudre le mystère de sa présence et vaincre les esprits maléfiques. Le film est rempli de scènes effrayantes et surnaturelles, de suspense et de tension. Les personnages sont confrontés à des situations de plus en plus terrifiantes et doivent faire face à leurs propres faiblesses pour espérer s'en sortir. Le suspense et l'horreur sont maintenus jusqu'à la fin du film, offrant un frissonnant voyage dans l'inconnu.\"\n",
    "titre_4 = \"La Maison Hantée\"\n",
    "\n",
    "# create a dataframe with the two new movie with two columns, synopsis and title\n",
    "df_new = pd.DataFrame()\n",
    "df_new[\"synopsis\"] = [synopsis, synopsis_2, synopsis_3, synopsis_4]\n",
    "df_new[\"titre\"] = [titre, titre_2, titre_3, titre_4]\n",
    "\n",
    "# process the dataframe\n",
    "df_new = process_df(df_new, train = False)\n",
    "\n",
    "# predict the genre\n",
    "bow_X_new = vectorizer.transform(df_new[\"synopsis_title\"])\n",
    "y_pred_new = model.predict(bow_X_new)\n",
    "\n",
    "print(\"Predicted genres : \", y_pred_new)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our model has a score of 0.49. For a first model, it is not bad. We will work with this model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested the model on some custom data and it seems to work well. It seems that the synopsis needs to be long enough to be able to predict the genre of the movie."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another Approach\n",
    "\n",
    "We will now use `transformers` to vectorize the data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synopsis_title</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>visite a istanbul celebre detective belge herc...</td>\n",
       "      <td>policier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jeune homme origine modeste accuse meurtre per...</td>\n",
       "      <td>drame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lorsque marielaure mere quatre jeunes enfants ...</td>\n",
       "      <td>drame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vagabond eprend belle jeune vendeuse fleurs av...</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>histoire vraie carl brashear premier afro amer...</td>\n",
       "      <td>biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>suite lucy lucy 2</td>\n",
       "      <td>science fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>navette spatiale americaine moonraker confiee ...</td>\n",
       "      <td>science fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>histoire communaute italienne annees 60 bronx ...</td>\n",
       "      <td>drame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>comme veut ancienne tradition vieille orin att...</td>\n",
       "      <td>drame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>apres mort petit ami lucia serveuse a madrid d...</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2875 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         synopsis_title            genre\n",
       "0     visite a istanbul celebre detective belge herc...         policier\n",
       "1     jeune homme origine modeste accuse meurtre per...            drame\n",
       "2     lorsque marielaure mere quatre jeunes enfants ...            drame\n",
       "3     vagabond eprend belle jeune vendeuse fleurs av...          romance\n",
       "4     histoire vraie carl brashear premier afro amer...           biopic\n",
       "...                                                 ...              ...\n",
       "2870                                  suite lucy lucy 2  science fiction\n",
       "2871  navette spatiale americaine moonraker confiee ...  science fiction\n",
       "2872  histoire communaute italienne annees 60 bronx ...            drame\n",
       "2873  comme veut ancienne tradition vieille orin att...            drame\n",
       "2874  apres mort petit ami lucia serveuse a madrid d...          romance\n",
       "\n",
       "[2875 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train_2 = pd.read_csv(\"../data/allocine_genres_train.csv\")\n",
    "\n",
    "df_train_2 = process_transformer(df_train_2)\n",
    "\n",
    "df_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = sorted(df_train_2[\"genre\"].unique())\n",
    "id_to_genre = {i:genre for i, genre in enumerate(genres)}\n",
    "genre_to_id = {genre:i for i, genre in enumerate(genres)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batch_size = 8\n",
    "scale = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label\n",
      "0  visite a istanbul celebre detective belge herc...      6\n",
      "1  jeune homme origine modeste accuse meurtre per...      3\n",
      "2  lorsque marielaure mere quatre jeunes enfants ...      3\n",
      "3  vagabond eprend belle jeune vendeuse fleurs av...      7\n",
      "4  histoire vraie carl brashear premier afro amer...      0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Features, Value, ClassLabel, Dataset, DatasetDict\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "# from csv\n",
    "\n",
    "\n",
    "\n",
    "data_to_use = pd.DataFrame()\n",
    "data_to_use['text'] = df_train_2.synopsis_title\n",
    "data_to_use['label'] = df_train_2.genre.map(genre_to_id)\n",
    "\n",
    "print(data_to_use.head())\n",
    "\n",
    "\n",
    "genre_features = Features({'text': Value('string'), \n",
    "                              'label': ClassLabel(names=genres)})\n",
    "\n",
    "data = Dataset.from_pandas(data_to_use, features=genre_features)\n",
    "data = data.train_test_split(test_size=0.2, shuffle=True, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['biopic', 'comédie', 'documentaire', 'drame', 'historique', 'horreur', 'policier', 'romance', 'science fiction'], id=None)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'fils magistrat hank palmer grand avocat revient petite ville enfance pere a revu depuis longtemps soupconne meurtre decide alors mener enquete decouvrir verite chemin faisant renoue famille laquelle pris distances juge',\n",
       " 'label': 3}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "model_name = \"camembert-base\"\n",
    "\n",
    "# You can replace \"camembert-base\" with any other model from the table, e.g. \"camembert/camembert-large\".\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[5, 976, 21839, 616, 13545, 17200, 81, 221, 6146, 2151, 354, 285, 4793, 2536, 35, 33, 15566, 176, 892, 3438, 286, 1349, 324, 6897, 8, 9739, 183, 3532, 22, 3452, 35, 8, 20395, 3762, 1737, 1111, 1208, 31951, 401, 745, 523, 14532, 2204, 6, 1, 1, 1, 1, 1, 1, 1], [5, 18, 364, 4177, 2812, 2800, 270, 33, 217, 10259, 528, 1375, 610, 20976, 613, 330, 244, 12774, 22103, 128, 5016, 289, 13833, 108, 194, 304, 2812, 455, 2940, 18, 364, 4177, 1281, 1719, 291, 128, 599, 1604, 836, 5241, 1016, 11874, 10, 32, 13023, 4443, 111, 25786, 2800, 270, 6]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(data['train'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e7ba50eb8645e3bfd9ba25783aafe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2300 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c214399acd846ada3d789052cb3fa15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/575 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = data.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '▁fils', '▁magistrat', '▁h', 'ank', '▁palme', 'r', '▁grand', '▁avocat', '▁revient', '▁petite', '▁ville', '▁enfance', '▁per', 'e', '▁a', '▁revu', '▁depuis', '▁longtemps', '▁sou', 'p', 'con', 'ne', '▁meurtre', '▁de', 'cide', '▁alors', '▁mener', '▁en', 'quet', 'e', '▁de', 'couvrir', '▁ver', 'ite', '▁chemin', '▁faisant', '▁renoue', '▁famille', '▁laquelle', '▁pris', '▁distances', '▁juge', '</s>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n",
      "fils magistrat hank palmer grand avocat revient petite ville enfance pere a revu depuis longtemps soupconne meurtre decide alors mener enquete decouvrir verite chemin faisant renoue famille laquelle pris distances juge\n"
     ]
    }
   ],
   "source": [
    "# Affichage des tokens. XML-Roberta utilise l'algorithm BPE (Byte Pair Encoding) pour encoder les mots\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_datasets['train'][0]['input_ids'])\n",
    "print(tokens)\n",
    "print(tokenized_datasets['train'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32005"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# empty the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(genres), id2label=id_to_genre, label2id=genre_to_id).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elmah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d696e56c4c194de09401e9b12313b5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1728 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6333d5d2d72a4bf893889754f9d0dd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6739786863327026, 'eval_accuracy': 0.44, 'eval_runtime': 7.5726, 'eval_samples_per_second': 75.932, 'eval_steps_per_second': 9.508, 'epoch': 1.0}\n",
      "{'loss': 1.7747, 'learning_rate': 1.4212962962962964e-05, 'epoch': 1.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ca43207b904c0097625933ebfb1b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4186497926712036, 'eval_accuracy': 0.5356521739130434, 'eval_runtime': 7.6328, 'eval_samples_per_second': 75.332, 'eval_steps_per_second': 9.433, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41d665e0ee54abf8ea7b1f44627699d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3131301403045654, 'eval_accuracy': 0.5634782608695652, 'eval_runtime': 7.6422, 'eval_samples_per_second': 75.24, 'eval_steps_per_second': 9.421, 'epoch': 3.0}\n",
      "{'loss': 1.2017, 'learning_rate': 8.425925925925926e-06, 'epoch': 3.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4ad5ff3a1749b38130e11841363343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2766015529632568, 'eval_accuracy': 0.5652173913043478, 'eval_runtime': 7.6666, 'eval_samples_per_second': 75.001, 'eval_steps_per_second': 9.391, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73be941dc9942418a362ef1af9a4a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2734897136688232, 'eval_accuracy': 0.5843478260869566, 'eval_runtime': 7.6476, 'eval_samples_per_second': 75.187, 'eval_steps_per_second': 9.415, 'epoch': 5.0}\n",
      "{'loss': 0.8882, 'learning_rate': 2.6388888888888893e-06, 'epoch': 5.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a84a5c4e7b8465d8b4bbc6b98fa48fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3008217811584473, 'eval_accuracy': 0.5669565217391305, 'eval_runtime': 7.6423, 'eval_samples_per_second': 75.239, 'eval_steps_per_second': 9.421, 'epoch': 6.0}\n",
      "{'train_runtime': 711.4249, 'train_samples_per_second': 19.398, 'train_steps_per_second': 2.429, 'train_loss': 1.2166013541045013, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1728, training_loss=1.2166013541045013, metrics={'train_runtime': 711.4249, 'train_samples_per_second': 19.398, 'train_steps_per_second': 2.429, 'train_loss': 1.2166013541045013, 'epoch': 6.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cebc05315134711a94c04da3c10fabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/72 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synopsis_title</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ville new york detective john smith piste dun ...</td>\n",
       "      <td>policier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>suivons marie curie debuts pologne alors quell...</td>\n",
       "      <td>biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sophie jeune femme ambitieuse travaille grande...</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>groupe damis decide passer weekend vieille mai...</td>\n",
       "      <td>horreur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      synopsis_title     preds\n",
       "0  ville new york detective john smith piste dun ...  policier\n",
       "1  suivons marie curie debuts pologne alors quell...    biopic\n",
       "2  sophie jeune femme ambitieuse travaille grande...   romance\n",
       "3  groupe damis decide passer weekend vieille mai...   horreur"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "trainer.save_model(\"./trained_model/camembert-base\")\n",
    "\n",
    "preds_output = trainer.predict(tokenized_datasets['test'])\n",
    "\n",
    "# compute the accuracy\n",
    "preds = np.argmax(preds_output.predictions, axis=1)\n",
    "labels = preds_output.label_ids\n",
    "accuracy_score(labels, preds)\n",
    "\n",
    "# create a pipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline('text-classification', model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# lets try with a new synopsis\n",
    "synopsis = \"Dans la ville de New York, le détective John Smith est sur la piste d'un tueur en série qui terrorise la ville depuis plusieurs mois. Alors que l'enquête piétine, le meurtrier continue de sévir et les victimes s'accumulent. John, qui est hanté par ses propres démons, est déterminé à arrêter le tueur avant qu'il ne frappe à nouveau. Au fil de l'enquête, John rencontre plusieurs personnages suspects, dont une ex-petite amie du tueur et un membre influent de la mafia locale. Il doit naviguer dans un monde sombre et dangereux pour découvrir la vérité sur l'identité du tueur. Alors que les indices s'accumulent et que la pression monte, John doit faire face à ses propres démons intérieurs et aux doutes de ses collègues. Dans une course contre la montre, il doit résoudre le mystère avant qu'il ne soit trop tard et que le tueur ne frappe de nouveau. Le film est rempli de suspense, de tension et de rebondissements jusqu'à son dénouement final choquant.\"\n",
    "titre = \"Au coeur de la nuit\"\n",
    "\n",
    "synopsis_2 = \"Nous suivons Marie Curie dès ses débuts en Pologne, alors qu'elle doit lutter contre les préjugés de genre pour poursuivre ses études scientifiques. Elle rencontre ensuite Pierre Curie, un physicien français, et ils tombent amoureux. Ensemble, ils commencent à travailler sur la radioactivité et découvrent le radium et le polonium, pour lesquels ils reçoivent le prix Nobel de physique en 1903. Mais leur travail n'a pas été facile et ils ont dû surmonter de nombreux obstacles, notamment les préjugés de genre et les réticences de la communauté scientifique. Ils ont également dû faire face à des tragédies personnelles, notamment la mort prématurée de Pierre. Après la mort de Pierre, Marie poursuit ses recherches et devient la première femme professeure à la Sorbonne. Elle reçoit également un deuxième prix Nobel, cette fois en chimie, pour son travail sur les éléments radioactifs. Le film montre comment Marie Curie a changé la face de la science et a ouvert la voie à d'autres femmes scientifiques. Mais il montre également les sacrifices qu'elle a dû faire pour y parvenir, notamment la lutte pour concilier son travail et sa vie de famille. Le film est une célébration de la vie extraordinaire de Marie Curie, une femme qui a brisé les barrières et ouvert la voie à de nouvelles découvertes scientifiques\"\n",
    "titre_2 = \"La vie extraordinaire de Marie Curie\"\n",
    "\n",
    "synopsis_3 = \"Sophie est une jeune femme ambitieuse qui travaille dans une grande entreprise. Elle est passionnée par son travail et sa vie sentimentale est au second plan. Un jour, elle rencontre Jake, un artiste bohème et charismatique. Malgré leurs différences, ils sont attirés l'un par l'autre et commencent une relation. Leur amour est intense et passionné, mais leur relation est mise à rude épreuve par les différences de leurs vies. Sophie doit naviguer dans le monde des arts de Jake, qui est très différent de son monde d'affaires. Et Jake doit faire face aux attentes de Sophie en matière de stabilité et de sécurité financière. Alors que leur relation devient de plus en plus sérieuse, ils doivent faire face à des défis imprévus qui mettent leur amour à l'épreuve. Ils doivent trouver un équilibre entre leurs vies et leurs rêves, tout en restant fidèles l'un à l'autre. Le film montre comment l'amour peut être imprévisible et inattendu, et comment il peut nous amener à repenser nos priorités et nos choix de vie. Les personnages principaux sont confrontés à des choix difficiles, mais ils sont prêts à tout pour leur amour. Le film est rempli de scènes romantiques, de moments d'humour et d'émotion, et offre une belle réflexion sur la vie et l'amour.\"\n",
    "titre_3 = \"Un Amour Inattendu\"\n",
    "\n",
    "synopsis_4 = \"Un groupe d'amis décide de passer un week-end dans une vieille maison isolée dans les bois. Mais dès leur arrivée, ils commencent à ressentir une étrange présence et à entendre des bruits inexpliqués. Bientôt, ils se rendent compte que la maison est hantée par des esprits maléfiques qui cherchent à les effrayer et à les tuer.Les amis tentent de quitter la maison, mais ils se retrouvent pris au piège par des phénomènes paranormaux terrifiants. Ils découvrent des indices sur le passé sombre de la maison et sur les esprits qui la hantent. Mais plus ils enquêtent, plus les esprits deviennent violents. Les amis doivent alors faire face à leurs peurs les plus profondes et unir leurs forces pour survivre aux attaques des esprits maléfiques. Ils se rendent compte que pour échapper à la maison hantée, ils doivent résoudre le mystère de sa présence et vaincre les esprits maléfiques. Le film est rempli de scènes effrayantes et surnaturelles, de suspense et de tension. Les personnages sont confrontés à des situations de plus en plus terrifiantes et doivent faire face à leurs propres faiblesses pour espérer s'en sortir. Le suspense et l'horreur sont maintenus jusqu'à la fin du film, offrant un frissonnant voyage dans l'inconnu.\"\n",
    "titre_4 = \"La Maison Hantée\"\n",
    "\n",
    "# create a dataframe with the two new movie with two columns, synopsis and title\n",
    "df_new = pd.DataFrame()\n",
    "df_new[\"synopsis\"] = [synopsis, synopsis_2, synopsis_3, synopsis_4]\n",
    "df_new[\"titre\"] = [titre, titre_2, titre_3, titre_4]\n",
    "\n",
    "\n",
    "# process the dataframe\n",
    "df_new = process_transformer(df_new, train = False)\n",
    "\n",
    "\n",
    "# predict the genre\n",
    "df_new[\"preds\"] = df_new[\"synopsis_title\"].apply(lambda x: classifier(x)[0][\"label\"])\n",
    "\n",
    "# print the results\n",
    "df_new\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elmah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\transformers\\pipelines\\base.py:1070: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# now test the classifier on the test set\n",
    "df_test = pd.read_csv(\"../data/allocine_genres_test.csv\")\n",
    "\n",
    "# process the dataframe\n",
    "df_test = process_transformer(df_test, train = True)\n",
    "\n",
    "# save the dataframe\n",
    "df_test.to_csv(\"../data/allocine_genres_test_processed.csv\", index = False)\n",
    "\n",
    "# predict the genre\n",
    "df_test[\"predicted_genre\"] = df_test[\"synopsis_title\"].apply(lambda x: classifier(x)[0][\"label\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5924895688456189\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synopsis_title</th>\n",
       "      <th>genre</th>\n",
       "      <th>predicted_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gilbert grape vit a endora iowa famille depuis...</td>\n",
       "      <td>romance</td>\n",
       "      <td>drame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aventure a fois complexe mysterieuse plusieurs...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>science fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a mort mere anne fait decouverte bouleverse ph...</td>\n",
       "      <td>romance</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christiane jeune berlinoise treize ans vit tre...</td>\n",
       "      <td>biopic</td>\n",
       "      <td>drame</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apres voyage mouvemente entre passe present fu...</td>\n",
       "      <td>science fiction</td>\n",
       "      <td>science fiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      synopsis_title            genre  \\\n",
       "0  gilbert grape vit a endora iowa famille depuis...          romance   \n",
       "1  aventure a fois complexe mysterieuse plusieurs...  science fiction   \n",
       "2  a mort mere anne fait decouverte bouleverse ph...          romance   \n",
       "3  christiane jeune berlinoise treize ans vit tre...           biopic   \n",
       "4  apres voyage mouvemente entre passe present fu...  science fiction   \n",
       "\n",
       "   predicted_genre  \n",
       "0            drame  \n",
       "1  science fiction  \n",
       "2          romance  \n",
       "3            drame  \n",
       "4  science fiction  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# check the accuracy\n",
    "print(accuracy_score(df_test[\"genre\"], df_test[\"predicted_genre\"]))\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sans Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = sorted(df_train[\"genre\"].unique())\n",
    "id_to_genre = {i:genre for i, genre in enumerate(genres)}\n",
    "genre_to_id = {genre:i for i, genre in enumerate(genres)}\n",
    "\n",
    "# parameters\n",
    "batch_size = 8\n",
    "scale = 0.2\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Features, Value, ClassLabel, Dataset, DatasetDict\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "\n",
    "data_to_use = pd.DataFrame()\n",
    "data_to_use['text'] = df_train.synopsis_title\n",
    "data_to_use['label'] = df_train.genre.map(genre_to_id)\n",
    "\n",
    "print(data_to_use.head())\n",
    "\n",
    "\n",
    "genre_features = Features({'text': Value('string'), \n",
    "                              'label': ClassLabel(names=genres)})\n",
    "\n",
    "data = Dataset.from_pandas(data_to_use, features=genre_features)\n",
    "data = data.train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "\n",
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "\n",
    "model_name = \"camembert-base\"\n",
    "\n",
    "# You can replace \"camembert-base\" with any other model from the table, e.g. \"camembert/camembert-large\".\n",
    "tokenizer = CamembertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "tokenize(data['train'][:2])\n",
    "\n",
    "tokenized_datasets = data.map(tokenize, batched=True, batch_size=None)\n",
    "J\n",
    "# Affichage des tokens. XML-Roberta utilise l'algorithm BPE (Byte Pair Encoding) pour encoder les mots\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_datasets['train'][0]['input_ids'])\n",
    "print(tokens)\n",
    "print(tokenized_datasets['train'][0]['text'])\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    return acc\n",
    "# empty the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(genres), id2label=id_to_genre, label2id=genre_to_id).to(device)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    )\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "trainer.evaluate()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On découvre que le modèle sans lemmatisation est plus performant que le modèle avec lemmatisation. Ceci est dû au fait que le modèle avec lemmatisation a tendance à supprimer des mots qui sont importants pour la prédiction du genre du film."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the result in a csv file\n",
    "df_test.to_csv(\"../data/allocine_genres_test_predicted.csv\", index = False)\n",
    "\n",
    "df_final = pd.read_csv(\"../data/allocine_genres_test.csv\")  \n",
    "\n",
    "df_final[\"predicted_genre\"] = df_test[\"predicted_genre\"]\n",
    "\n",
    "df_final.to_csv(\"../data/allocine_genres_test_predicted.csv\", index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do the same but we wont't stem the words. We will also use the `cmarkea/distilcamembert-base` model.\n",
    "You should probably run this part on google colab with a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2 = pd.read_csv(\"../data/allocine_genres_train.csv\")\n",
    "\n",
    "df_train_2 = process_transformer(df_train_2)\n",
    "\n",
    "genres = sorted(df_train[\"genre\"].unique())\n",
    "id_to_genre = {i:genre for i, genre in enumerate(genres)}\n",
    "genre_to_id = {genre:i for i, genre in enumerate(genres)}\n",
    "\n",
    "# parameters\n",
    "batch_size = 8\n",
    "scale = 0.2\n",
    "\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Features, Value, ClassLabel, Dataset, DatasetDict\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "\n",
    "data_to_use = pd.DataFrame()\n",
    "data_to_use['text'] = df_train_2.synopsis_title\n",
    "data_to_use['label'] = df_train_2.genre.map(genre_to_id)\n",
    "\n",
    "print(data_to_use.head())\n",
    "\n",
    "\n",
    "genre_features = Features({'text': Value('string'), \n",
    "                              'label': ClassLabel(names=genres)})\n",
    "\n",
    "data = Dataset.from_pandas(data_to_use, features=genre_features)\n",
    "data = data.train_test_split(test_size=0.2, shuffle=True, seed=42)\n",
    "\n",
    "data['train'].features\n",
    "data['train'][0]\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cmarkea/distilcamembert-base\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"cmarkea/distilcamembert-base\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "tokenize(data['train'][:2])\n",
    "\n",
    "tokenized_datasets = data.map(tokenize, batched=True, batch_size=None)\n",
    "\n",
    "# Affichage des tokens. XML-Roberta utilise l'algorithm BPE (Byte Pair Encoding) pour encoder les mots\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_datasets['train'][0]['input_ids'])\n",
    "print(tokens)\n",
    "print(tokenized_datasets['train'][0]['text'])\n",
    "\n",
    "tokenizer.vocab_size\n",
    "tokenizer.model_max_length\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "# empty the GPU cache\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['test'],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
