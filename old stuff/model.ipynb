{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the data\n",
    "\n",
    "Now that we have a dataframe with 3 columns :  `tokenized` (title + synopsis), `genre` and `length`, we can vectorize the data. We will use the `Bag-of-Words` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sys\n",
    "sys.path.append('../preprocessing')\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the libraries and getting the preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synopsis</th>\n",
       "      <th>genre</th>\n",
       "      <th>titre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>En visite à Istanbul , le célèbre détective be...</td>\n",
       "      <td>policier</td>\n",
       "      <td>Le Crime de l' Orient - Express</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Un jeune homme d' origine modeste est accusé d...</td>\n",
       "      <td>drame</td>\n",
       "      <td>12 hommes en colère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lorsque Marie-Laure , mère de quatre jeunes en...</td>\n",
       "      <td>drame</td>\n",
       "      <td>Après moi le bonheur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Un vagabond s’ éprend d’ une belle et jeune ve...</td>\n",
       "      <td>romance</td>\n",
       "      <td>Les Lumières de la ville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L' histoire vraie de Carl Brashear , premier A...</td>\n",
       "      <td>biopic</td>\n",
       "      <td>Les Chemins de la dignité</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            synopsis     genre  \\\n",
       "0  En visite à Istanbul , le célèbre détective be...  policier   \n",
       "1  Un jeune homme d' origine modeste est accusé d...     drame   \n",
       "2  Lorsque Marie-Laure , mère de quatre jeunes en...     drame   \n",
       "3  Un vagabond s’ éprend d’ une belle et jeune ve...   romance   \n",
       "4  L' histoire vraie de Carl Brashear , premier A...    biopic   \n",
       "\n",
       "                             titre  \n",
       "0  Le Crime de l' Orient - Express  \n",
       "1              12 hommes en colère  \n",
       "2             Après moi le bonheur  \n",
       "3         Les Lumières de la ville  \n",
       "4        Les Chemins de la dignité  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('../preprocessing/preprocessed_data.csv')\n",
    "df_test = pd.read_csv('../preprocessing/preprocessed_data_test.csv')\n",
    "df_2 = pd.read_csv('../data/allocine_genres_train.csv')\n",
    "df_2_test = pd.read_csv('../data/allocine_genres_test.csv')\n",
    "\n",
    "# keep only the columns we need\n",
    "df_2 = df_2[['synopsis', 'genre','titre']]\n",
    "df_2_test = df_2_test[['synopsis','genre', 'titre']]\n",
    "\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22608\n",
      "(2300, 22608) (575, 22608) (2300,) (575,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elmah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:  0.43130434782608695\n",
      "LogisticRegression Test:  0.4909596662030598\n",
      "--------------------\n",
      "RandomForestClassifier:  0.36695652173913046\n",
      "RandomForestClassifier Test:  0.4102920723226704\n",
      "--------------------\n",
      "SVC:  0.3130434782608696\n",
      "SVC Test:  0.35465924895688455\n",
      "--------------------\n",
      "MultinomialNB:  0.4295652173913043\n",
      "MultinomialNB Test:  0.42141863699582754\n",
      "--------------------\n",
      "KNeighborsClassifier:  0.16521739130434782\n",
      "KNeighborsClassifier Test:  0.1835883171070932\n",
      "--------------------\n",
      "DecisionTreeClassifier:  0.27304347826086955\n",
      "DecisionTreeClassifier Test:  0.30737134909596664\n",
      "--------------------\n",
      "XGBClassifier:  0.40869565217391307\n",
      "XGBClassifier Test:  0.4617524339360223\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# fit the vectorizer on the text\n",
    "vectorizer.fit(df_2['synopsis'])\n",
    "\n",
    "# get all the unique words\n",
    "print(len(vectorizer.get_feature_names_out()))\n",
    "\n",
    "# transform train and test data into vectors\n",
    "X_train = vectorizer.transform(df_2['synopsis'])\n",
    "X_test = vectorizer.transform(df_2_test['synopsis'])\n",
    "\n",
    "# initialize the LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit the encoder on the train labels\n",
    "le.fit(df_2['genre'])\n",
    "\n",
    "# transform the train and test labels\n",
    "y_train = le.transform(df_2['genre'])\n",
    "\n",
    "# split the train data into train and validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "\n",
    "# print the shapes\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# Path: model\\model.ipynb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# initialize the model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit the model on the train data\n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "# make predictions on the validation data\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"LogisticRegression: \", accuracy_score(y_val, preds))\n",
    "\n",
    "# test the model on the test data\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "# convert the predictions to text\n",
    "preds_test = le.inverse_transform(preds_test)\n",
    "\n",
    "# print the accuracy score\n",
    "# print(df_2_test['genre'])\n",
    "# print(preds_test)\n",
    "print(\"LogisticRegression Test: \", accuracy_score(df_2_test['genre'], preds_test))\n",
    "print(\"--------------------\")\n",
    "\n",
    "# test other models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# initialize the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model on the train data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the validation data\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"RandomForestClassifier: \", accuracy_score(y_val, preds))\n",
    "\n",
    "# test the model on the test data\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "# convert the predictions to text\n",
    "preds_test = le.inverse_transform(preds_test)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"RandomForestClassifier Test: \", accuracy_score(df_2_test['genre'], preds_test))\n",
    "print(\"--------------------\")\n",
    "\n",
    "\n",
    "# test other models\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# initialize the model\n",
    "model = SVC()\n",
    "\n",
    "# fit the model on the train data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the validation data\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"SVC: \", accuracy_score(y_val, preds))\n",
    "\n",
    "# test the model on the test data\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "# convert the predictions to text\n",
    "preds_test = le.inverse_transform(preds_test)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"SVC Test: \", accuracy_score(df_2_test['genre'], preds_test))\n",
    "print(\"--------------------\")\n",
    "\n",
    "# test other models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# initialize the model\n",
    "model = MultinomialNB()\n",
    "\n",
    "# fit the model on the train data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the validation data\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"MultinomialNB: \", accuracy_score(y_val, preds))\n",
    "\n",
    "# test the model on the test data\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "# convert the predictions to text\n",
    "preds_test = le.inverse_transform(preds_test)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"MultinomialNB Test: \", accuracy_score(df_2_test['genre'], preds_test))\n",
    "print(\"--------------------\")\n",
    "\n",
    "# test other models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# initialize the model\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# fit the model on the train data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the validation data\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"KNeighborsClassifier: \", accuracy_score(y_val, preds))\n",
    "\n",
    "# test the model on the test data\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "# convert the predictions to text\n",
    "preds_test = le.inverse_transform(preds_test)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"KNeighborsClassifier Test: \", accuracy_score(df_2_test['genre'], preds_test))\n",
    "print(\"--------------------\")\n",
    "\n",
    "# test other models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# initialize the model\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model on the train data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the validation data\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"DecisionTreeClassifier: \", accuracy_score(y_val, preds))\n",
    "\n",
    "# test the model on the test data\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "# convert the predictions to text\n",
    "preds_test = le.inverse_transform(preds_test)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"DecisionTreeClassifier Test: \", accuracy_score(df_2_test['genre'], preds_test))\n",
    "print(\"--------------------\")\n",
    "\n",
    "# test other models\n",
    "# use xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# initialize the model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# fit the model on the train data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the validation data\n",
    "preds = model.predict(X_val)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"XGBClassifier: \", accuracy_score(y_val, preds))\n",
    "\n",
    "# test the model on the test data\n",
    "preds_test = model.predict(X_test)\n",
    "\n",
    "# convert the predictions to text\n",
    "preds_test = le.inverse_transform(preds_test)\n",
    "\n",
    "# print the accuracy score\n",
    "print(\"XGBClassifier Test: \", accuracy_score(df_2_test['genre'], preds_test))\n",
    "print(\"--------------------\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a `CountVectorizer` object and fit it to the `tokenized` column of the dataframe. This will create a vocabulary of all the unique words in the `tokenized` column. We then use the `transform()` method to convert the text data into a matrix of token counts. This matrix is a sparse matrix, which means that it contains a lot of zeros. We can convert this matrix to a dense matrix using the `toarray()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized</th>\n",
       "      <th>genre</th>\n",
       "      <th>length</th>\n",
       "      <th>10e</th>\n",
       "      <th>1er</th>\n",
       "      <th>25em</th>\n",
       "      <th>2e</th>\n",
       "      <th>3e</th>\n",
       "      <th>3em</th>\n",
       "      <th>4h44</th>\n",
       "      <th>...</th>\n",
       "      <th>évoluent</th>\n",
       "      <th>évoqu</th>\n",
       "      <th>évoquent</th>\n",
       "      <th>ête</th>\n",
       "      <th>être</th>\n",
       "      <th>île</th>\n",
       "      <th>œil</th>\n",
       "      <th>œuf</th>\n",
       "      <th>œuvr</th>\n",
       "      <th>genre_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['visit', 'célebr', 'détect', 'belg', 'embarqu...</td>\n",
       "      <td>policier</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['homm', 'coler', 'jeun', 'homm', 'd', 'origin...</td>\n",
       "      <td>drame</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['apres', 'bonheur', 'lorsqu', 'mer', 'quatr',...</td>\n",
       "      <td>drame</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['vagabond', 'éprend', 'bel', 'jeun', 'vendeux...</td>\n",
       "      <td>romance</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['histoir', 'vrai', 'premi', 'afro', 'américai...</td>\n",
       "      <td>biopic</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 9730 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tokenized     genre  length  10e  \\\n",
       "0  ['visit', 'célebr', 'détect', 'belg', 'embarqu...  policier      64    0   \n",
       "1  ['homm', 'coler', 'jeun', 'homm', 'd', 'origin...     drame      58    0   \n",
       "2  ['apres', 'bonheur', 'lorsqu', 'mer', 'quatr',...     drame      71    0   \n",
       "3  ['vagabond', 'éprend', 'bel', 'jeun', 'vendeux...   romance      24    0   \n",
       "4  ['histoir', 'vrai', 'premi', 'afro', 'américai...    biopic      35    0   \n",
       "\n",
       "   1er  25em  2e  3e  3em  4h44  ...  évoluent  évoqu  évoquent  ête  être  \\\n",
       "0    0     0   0   0    0     0  ...         0      0         0    0     0   \n",
       "1    0     0   0   0    0     0  ...         0      0         0    0     1   \n",
       "2    0     0   0   0    0     0  ...         0      0         0    0     0   \n",
       "3    0     0   0   0    0     0  ...         0      0         0    0     0   \n",
       "4    0     0   0   0    0     0  ...         0      0         0    0     0   \n",
       "\n",
       "   île  œil  œuf  œuvr  genre_encoded  \n",
       "0    0    0    0     0              6  \n",
       "1    0    0    0     0              3  \n",
       "2    0    0    0     0              3  \n",
       "3    0    0    0     0              7  \n",
       "4    0    0    0     0              0  \n",
       "\n",
       "[5 rows x 9730 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the tokenized column\n",
    "bow = vectorizer.fit_transform(df['tokenized'])\n",
    "\n",
    "# Convert the sparse matrix to a DataFrame\n",
    "bow_df = pd.DataFrame(bow.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the BoW DataFrame with the original DataFrame\n",
    "df_bow = pd.concat([df, bow_df], axis=1)\n",
    "\n",
    "# Initialize a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the genre column\n",
    "df_bow['genre_encoded'] = label_encoder.fit_transform(df['genre'])\n",
    "\n",
    "df_bow.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then split the data into training and testing sets. We will use 80% of the data for training and 20% for testing. We will also set the `random_state` parameter to 42 so that we can reproduce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 9727) (575, 9727) (2300,) (575,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_bow.drop(['genre', 'tokenized', 'genre_encoded'], axis=1), \n",
    "                                                  df_bow['genre_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll first start with a basic naive model. We will just see what class is the most frequent and predict that class for all the test data. We will then use the `accuracy_score` function to calculate the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of dummy classifier: 0.1565217391304348\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Create dummy classifier that always predicts the most frequent class\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "# Fit the dummy classifier on the training data\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred_dummy = dummy_clf.predict(X_val)\n",
    "\n",
    "# Evaluate the performance of the dummy classifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "dummy_accuracy = accuracy_score(y_val, y_pred_dummy)\n",
    "print(\"Accuracy of dummy classifier:\", dummy_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing multiple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Naive Bayes classifier: 0.4747826086956522\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes   \n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a MultinomialNB object\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "nb_accuracy = nb_classifier.score(X_val, y_val)\n",
    "print(\"Accuracy of Naive Bayes classifier:\", nb_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of SVM classifier: 0.18956521739130436\n"
     ]
    }
   ],
   "source": [
    "#  SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create a SVC object\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "svc_accuracy = svc_classifier.score(X_val, y_val)\n",
    "print(\"Accuracy of SVM classifier:\", svc_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier: 0.49043478260869566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elmah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a LogisticRegression object\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "logreg_accuracy = logreg.score(X_val, y_val)\n",
    "print(\"Accuracy of Logistic Regression classifier:\", logreg_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest classifier: 0.42782608695652175\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Create a RandomForestClassifier object\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "rf_accuracy = rf_classifier.score(X_val, y_val)\n",
    "print(\"Accuracy of Random Forest classifier:\", rf_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost classifier: 0.4539130434782609\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create a XGBClassifier object\n",
    "xgb_classifier = XGBClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "xgb_accuracy = xgb_classifier.score(X_val, y_val)\n",
    "print(\"Accuracy of XGBoost classifier:\", xgb_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17869565217391306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\elmah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "5 fits failed out of a total of 25.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\elmah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\elmah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\dummy.py\", line 196, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Constant target value has to be specified when the constant strategy is used.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\elmah\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.17869565 0.12782609 0.17869565 0.10478261        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dummy_grid = {\n",
    "    'strategy': ['most_frequent', 'stratified', 'prior', 'uniform', 'constant']\n",
    "}\n",
    "dummy = DummyClassifier( random_state = 42)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "dummy_gs = GridSearchCV(dummy, param_grid = dummy_grid, cv = 5)\n",
    "dummy_gs.fit(X_train, y_train)\n",
    "print(dummy_gs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2300, 9727) (575, 9727) (2300,) (575,)\n",
      "Accuracy of Naive Bayes classifier: 0.18608695652173912\n",
      "Accuracy of SVM classifier: 0.1826086956521739\n",
      "Accuracy of Logistic Regression classifier: 0.4765217391304348\n",
      "Accuracy of Random Forest classifier: 0.4469565217391304\n"
     ]
    }
   ],
   "source": [
    "# import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize a TfidfVectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the tokenized column\n",
    "tfidf = tfidf_vectorizer.fit_transform(df['tokenized'])\n",
    "\n",
    "# Convert the tfidf matrix to a DataFrame\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Concatenate the tfidf DataFrame with the original DataFrame\n",
    "df_tfidf = pd.concat([df, tfidf_df], axis=1)\n",
    "\n",
    "# Initialize a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the genre column\n",
    "df_tfidf['genre_encoded'] = label_encoder.fit_transform(df['genre'])\n",
    "\n",
    "df_tfidf.head()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_tfidf.drop(['genre', 'tokenized', 'genre_encoded'], axis=1),\n",
    "                                                    df_tfidf['genre_encoded'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "\n",
    "# Create a MultinomialNB object\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "nb_accuracy = nb_classifier.score(X_val, y_val)\n",
    "print(\"Accuracy of Naive Bayes classifier:\", nb_accuracy)\n",
    "\n",
    "# Create a SVC object\n",
    "svc_classifier = SVC()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "svc_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "svc_accuracy = svc_classifier.score(X_val, y_val)\n",
    "\n",
    "print(\"Accuracy of SVM classifier:\", svc_accuracy)\n",
    "\n",
    "# Create a LogisticRegression object\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "logreg_accuracy = logreg.score(X_val, y_val)\n",
    "\n",
    "print(\"Accuracy of Logistic Regression classifier:\", logreg_accuracy)\n",
    "\n",
    "# Create a RandomForestClassifier object\n",
    "\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute the accuracy of the classifier\n",
    "rf_accuracy = rf_classifier.score(X_val, y_val)\n",
    "\n",
    "print(\"Accuracy of Random Forest classifier:\", rf_accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
